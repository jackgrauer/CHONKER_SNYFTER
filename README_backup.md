# CHONKER_SNYFTER v10.0 - Hybrid PDF Processing Pipeline

![Development Status](https://img.shields.io/badge/status-alpha-orange)
![Rust](https://img.shields.io/badge/rust-1.70%2B-orange)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)

```
  \___/
  [o-Â·-o]  ğŸ¹ CHONKER - The Cutest Document Processing Pipeline!
  (")~(") 
```

## Version Note

**CHONKER_SNYFTER v10.0 is a hybrid Rust-Python application with intelligent document routing and a modern terminal interface.**

## ğŸš€ Features

- **âš¡ Hybrid Architecture**: Sub-10ms fast path for 90% of documents + ML path for complex cases
- **ğŸ§  Intelligent Routing**: Automatic complexity analysis to choose optimal processing path
- **ğŸ’¾ Database Integration**: SQLite with full-text search and export capabilities
- **ğŸ–¥ï¸ CLI + TUI**: Command-line interface and terminal user interface
- **ğŸ“Š Analysis Ready**: Export to CSV/JSON/Parquet for data analysis
- **ğŸ Python Bridge**: Seamless integration with ML tools (Docling, Magic-PDF)

## ğŸ“Š Current Implementation Status

### âœ… Completed
- Basic Rust CLI structure with clap
- TUI framework with ratatui
- SQLite database integration
- Python bridge for complex document processing
- Command routing system
- Binary builds to `./target/debug/chonker`

### ğŸš§ In Progress
- Fast path PDF processing with pdfium-render
- Performance optimization for sub-10ms processing
- Full-text search implementation
- Parquet export functionality
- Redis caching layer

### ğŸ“… Planned
- Batch processing orchestration
- Advanced complexity scoring algorithm
- Multi-threaded document processing
- Web API interface

## ğŸ“ Project Structure
```
CHONKER_SNYFTER/
â”œâ”€â”€ Cargo.toml              # Rust project configuration
â”œâ”€â”€ src/                    # Rust source code
â”‚   â”œâ”€â”€ main.rs            # CLI entry point
â”‚   â”œâ”€â”€ lib.rs             # Library root
â”‚   â”œâ”€â”€ commands/          # CLI command implementations
â”‚   â”œâ”€â”€ tui/               # Terminal UI modules
â”‚   â””â”€â”€ database/          # SQLite integration
â”œâ”€â”€ target/                 # Rust build artifacts
â”‚   â””â”€â”€ debug/
â”‚       â””â”€â”€ chonker        # Compiled binary
â”œâ”€â”€ python/                 # Python components
â”‚   â”œâ”€â”€ chonker.py         # Complex document processing
â”‚   â””â”€â”€ snyfter.py         # AI extraction pipeline
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md              # This file
```

## ğŸš€ Quick Start

### Using Pre-built Binary
```bash
# If you have the compiled binary
./target/debug/chonker tui
```

### Building from Source
```bash
# Clone and build
git clone https://github.com/jackgrauer/CHONKER_SNYFTER
cd CHONKER_SNYFTER
cargo build
cargo run -- tui
```

### Python Components Setup
```bash
pip install -r requirements.txt
export ANTHROPIC_API_KEY=sk-ant-your-key-here
```

## ğŸ—ï¸ Architecture Overview

CHONKER_SNYFTER uses a hybrid Rust-Python architecture:

1. **Rust Core** (./target/debug/chonker)
   - CLI interface and argument parsing
   - Document routing based on complexity
   - SQLite database management
   - TUI for interactive processing
   - Fast path for simple PDFs (when complete)

2. **Python ML Pipeline** (python/)
   - Docling integration for complex documents
   - AI-powered extraction with Anthropic
   - Advanced table and layout recognition
   - Fallback processing for unsupported formats

3. **Routing Logic**
   - Simple PDFs â†’ Rust fast path (in development)
   - Complex documents â†’ Python ML pipeline
   - Automatic fallback on processing errors

## âš¡ Performance Goals

| Metric | Target | Current Status |
|--------|--------|----------------|
| Simple PDF processing |  10ms | ğŸš§ In Development |
| Complex document processing | 1-5s | âœ… Achieved (Python) |
| Concurrent requests | 1000+ | ğŸš§ Architecture ready |
| Cache hit rate | 80% | ğŸ“… Planned |
| Database queries |  1ms | âœ… Achieved |

## ğŸ’» Usage Examples

### Currently Working
```bash
# Launch TUI (framework ready, features in development)
cargo run -- tui
./target/debug/chonker tui

# Python processing (fully functional)
python python/chonker.py
python python/snyfter.py
```

### Coming Soon
```bash
# Fast PDF extraction
cargo run -- extract simple.pdf --tool rust --store

# Batch processing
cargo run -- batch process ./documents/
```

## ğŸ› ï¸ Dependencies

- Rust 1.70+
- Python 3.8+ (for ML path)
- SQLite
- Optional: Redis for caching

## ğŸ¯ Perfect For

- **Investigative Journalism**: Process massive policy documents under deadline pressure
- **Document Analysis**: Extract and verify data from complex PDFs
- **Batch Processing**: Handle large document collections efficiently
- **Research**: Maintain perfect traceability from source to analysis

## ğŸ¤ Contributing

The Rust implementation is actively being developed. Key areas needing help:
- Implementing pdfium-render integration for fast path
- Optimizing routing algorithm
- Adding comprehensive tests
- Improving TUI features

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

**ğŸ¯ Built for anxiety-free document processing with live monitoring and intelligent data extraction.**

# CHONKER_SNYFTER v10.0 - Hybrid PDF Processing Pipeline

![Development Status](https://img.shields.io/badge/status-alpha-orange)
![Rust](https://img.shields.io/badge/rust-1.70%2B-orange)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)

```
  \___/>
  [o-Â·-o]  ğŸ¹ CHONKER - The Cutest Document Processing Pipeline!
  (")~(") 
```

## Version Note

**CHONKER_SNYFTER v10.0 is a hybrid Rust-Python application with intelligent document routing and a modern terminal interface.**

## ğŸš€ Features

- **âš¡ Hybrid Architecture**: Sub-10ms fast path for 90% of documents + ML path for complex cases
- **ğŸ§  Intelligent Routing**: Automatic complexity analysis to choose optimal processing path
- **ğŸ’¾ Database Integration**: SQLite with full-text search and export capabilities
- **ğŸ–¥ï¸ CLI + TUI**: Command-line interface and terminal user interface
- **ğŸ“Š Analysis Ready**: Export to CSV/JSON/Parquet for data analysis
- **ğŸ Python Bridge**: Seamless integration with ML tools (Docling, Magic-PDF)

## ğŸ“Š Current Implementation Status

### âœ… Completed
- Basic Rust CLI structure with clap
- TUI framework with ratatui
- SQLite database integration
- Python bridge for complex document processing
- Command routing system
- Binary builds to `./target/debug/chonker`

### ğŸš§ In Progress
- Fast path PDF processing with pdfium-render
- Performance optimization for sub-10ms processing
- Full-text search implementation
- Parquet export functionality
- Redis caching layer

### ğŸ“… Planned
- Batch processing orchestration
- Advanced complexity scoring algorithm
- Multi-threaded document processing
- Web API interface

## ğŸ“ Project Structure
```
CHONKER_SNYFTER/
â”œâ”€â”€ Cargo.toml              # Rust project configuration
â”œâ”€â”€ src/                    # Rust source code
â”‚   â”œâ”€â”€ main.rs            # CLI entry point
â”‚   â”œâ”€â”€ lib.rs             # Library root
â”‚   â”œâ”€â”€ commands/          # CLI command implementations
â”‚   â”œâ”€â”€ tui/               # Terminal UI modules
â”‚   â””â”€â”€ database/          # SQLite integration
â”œâ”€â”€ target/                 # Rust build artifacts
â”‚   â””â”€â”€ debug/
â”‚       â””â”€â”€ chonker        # Compiled binary
â”œâ”€â”€ python/                 # Python components
â”‚   â”œâ”€â”€ chonker.py         # Complex document processing
â”‚   â””â”€â”€ snyfter.py         # AI extraction pipeline
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md              # This file
```

## ğŸš€ Quick Start

### Using Pre-built Binary
```bash
# If you have the compiled binary
./target/debug/chonker tui
```
### Building from Source
```bash
# Clone and build
git clone https://github.com/jackgrauer/CHONKER_SNYFTER
cd CHONKER_SNYFTER
cargo build
cargo run -- tui
```
### Python Components Setup
```bash
pip install -r requirements.txt
export ANTHROPIC_API_KEY=sk-ant-your-key-here
```

## ğŸ—ï¸ Architecture

**Fast Path (Rust Native)**:
- `pdfium-render` for PDF parsing
- Native text extraction
- Basic layout detection
- Target: 1-5ms per document

**Complex Path (Python ML)**:
- Advanced document understanding
- Table structure recognition
- Multi-column layout analysis
- Target: 1-5 seconds per document

**Smart Routing**:
- File size analysis
- Page count estimation
- Layout complexity scoring
- Automatic path selection

## ğŸ“Š Performance Goals

âœ… 90% of documents processed in < 10ms  
âœ… No regression in extraction quality  
âœ… Seamless fallback for complex documents  
âœ… Cache reduces repeated processing by 80%  
âœ… System handles 1000+ concurrent requests  

## ğŸ¯ Perfect For

- **Investigative Journalism**: Process massive policy documents under deadline pressure
- **Document Analysis**: Extract and verify data from complex PDFs
- **Batch Processing**: Handle large document collections efficiently
- **Research**: Maintain perfect traceability from source to analysis

## ğŸ› ï¸ Dependencies

- Rust 1.70+
- Python 3.8+ (for ML path)
- SQLite
- Optional: Redis for caching

Built with investigative journalism in mind - accuracy, speed, and verifiability above all else.
cd chonker-snyfter

# Install dependencies
pip install -r requirements.txt

# Set your API key for SNYFTER
export ANTHROPIC_API_KEY=sk-ant-your-key-here
```

### Basic Usage

1. **Process a document with CHONKER:**
   ```bash
   python chonker.py
   # Then: load document.pdf
   ```

2. **Extract data with SNYFTER:**
   ```bash
   python snyfter.py
   # Then: load â†’ classify â†’ extract â†’ export
   ```

## ğŸ“‹ Features

### ğŸ¹ CHONKER v6.0
- **Live Monitoring** - Real-time progress with anxiety-reducing heartbeat display
- **Smart Document Processing** - Docling integration with graceful fallbacks
- **Intelligent Chunking** - Respects word boundaries, optimized for AI processing
- **Entity Extraction** - 8 robust patterns (emails, phones, chemicals, etc.)
- **Keep-Awake System** - Prevents computer sleep during long processing
- **Cross-Platform** - Works on macOS, Windows, and Linux
- **Database Integration** - Optional DuckDB storage and search

### ğŸ­ SNYFTER v9.1
- **Adaptive Schema Discovery** - AI learns document structure as it processes
- **Two-Pass AI Processing** - Classification â†’ Extraction pipeline
- **Multiple Export Formats** - CSV, Excel, JSON with auto-generated loading scripts
- **Step-by-Step Interface** - Build extraction pipeline incrementally
- **Custom Configuration** - Tailored extraction rules and focus areas
- **Data Type Detection** - Environmental, financial, tabular data recognition

## ğŸ”§ Detailed Usage

### CHONKER Commands

| Command | Description |
|---------|-------------|
| `load` | Show available documents or load specific file |
| `load <filename>` | Process document with live monitoring |
| `list` | Show created chunks with previews |
| `show <n>` | Open specific chunk in editor |
| `search <term>` | Search entities across chunks |
| `info` | Display document processing summary |
| `export` | Export chunks for SNYFTER integration |
| `help` | Show all commands |

### SNYFTER Pipeline

1. **Load Chunks** (`load`)
   - Automatically finds CHONKER output
   - Supports loading specific chunks or ranges
   - Preview functionality to inspect content

2. **Classify Content** (`classify`)
   - AI-powered content type discovery
   - Adaptive schema that learns document patterns
   - Confidence scoring and reasoning

3. **Extract Data** (`extract`)
   - Structured data extraction based on classifications
   - Environmental, financial, and tabular data support
   - Automatic pattern recognition

4. **Configure Rules** (`config`) - Optional
   - Custom extraction instructions
   - Priority entity selection
   - Output format preferences

5. **Export Results** (`export`)
   - Python-ready datasets (CSV/Excel/JSON)
   - Auto-generated loading scripts
   - Summary reports

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ chonker.py              # Main CHONKER application
â”œâ”€â”€ snyfter.py              # Main SNYFTER application
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ saved_chonker_chunks/  # CHONKER output directory
â”‚   â”œâ”€â”€ chunk_1.txt
â”‚   â”œâ”€â”€ chunk_2.txt
â”‚   â””â”€â”€ ...
â””â”€â”€ snyfter_output/        # SNYFTER export directory
    â””â”€â”€ export_YYYYMMDD_HHMMSS/
        â”œâ”€â”€ environmental_data.csv
        â”œâ”€â”€ load_datasets.py
        â””â”€â”€ extraction_summary.txt
```

## ğŸ”‘ API Key Setup

SNYFTER requires an Anthropic API key for AI classification and extraction:

1. Get your API key: https://console.anthropic.com/
2. Set environment variable:
   ```bash
   # Linux/macOS
   export ANTHROPIC_API_KEY=sk-ant-your-key-here
   
   # Windows
   set ANTHROPIC_API_KEY=sk-ant-your-key-here
   ```
3. Test with: `python snyfter.py` then `apikey`

## ğŸš¨ Troubleshooting

### Common Issues

**CHONKER:**
- **Docling slow/hanging** â†’ Press Ctrl+C to use fallback processing
- **No chunks found** â†’ Check file permissions and supported formats
- **Memory issues** â†’ Process smaller files or increase system RAM

**SNYFTER:**
- **API key errors** â†’ Run `apikey` command to test configuration
- **No chunks found** â†’ Ensure CHONKER has been run first
- **Classification fails** â†’ Check internet connection and API key validity

### File Format Support

**CHONKER Supported Formats:**
- PDF (Docling + PyPDF2 fallback)
- DOCX (Docling)
- TXT, MD (native)

**Output Formats:**
- CHONKER: Text chunks in `saved_chonker_chunks/`
- SNYFTER: CSV, Excel, JSON with loading scripts

## ğŸ”§ Advanced Configuration

### Environment Variables

```bash
# Custom chunk output directory
export CHONKER_OUTPUT_DIR=/path/to/chunks

# API configuration
export ANTHROPIC_API_KEY=sk-ant-your-key
```

### Custom Extraction Patterns

CHONKER includes these entity patterns by default:
- Email addresses
- Phone numbers
- Dates
- Sample IDs
- Chemical names
- Concentrations
- Numbers

Add custom patterns by modifying the `SimpleEntityExtractor` class.

## ğŸ¤ Integration Workflow

1. **Document Processing**
   ```bash
   python chonker.py
   > load environmental_report.pdf
   ```

2. **Data Extraction**
   ```bash
   python snyfter.py
   > load
   > classify
   > extract
   > export csv
   ```

3. **Use Extracted Data**
   ```python
   # Auto-generated by SNYFTER
   exec(open('snyfter_output/export_*/load_datasets.py').read())
   
   # Your data is now available
   environmental_data.head()
   ```

## ğŸ“Š Example Output

**CHONKER Processing:**
- Input: `environmental_report.pdf` (2.3 MB)
- Output: 15 chunks, 127 entities found
- Processing time: 23.4s with live monitoring

**SNYFTER Extraction:**
- Discovered data types: environmental_lab_results, monitoring_well_coordinates
- Extracted datasets: environmental_data (156 rows Ã— 6 columns)
- Export: CSV + loading script + summary

## ğŸ› Development

### Running Tests
```bash
# Test CHONKER processing
python chonker.py
> load test_document.pdf

# Test SNYFTER pipeline
python snyfter.py
> apikey  # Verify API setup
> load
> status  # Check pipeline status
```

### Contributing
1. Fork the repository
2. Create feature branch
3. Test with sample documents
4. Submit pull request

## ğŸ“„ License

[Specify your license here]

## ğŸ†˜ Support

- **Issues**: Create GitHub issue with error logs
- **API Problems**: Check Anthropic console and billing
- **Performance**: Monitor system resources during processing

---

**ğŸ¯ Built for anxiety-free document processing with live monitoring and intelligent data extraction.**
>>>>>>> bc336c5a2d5c61d9d6676f7e7652451fb76fbbbc
